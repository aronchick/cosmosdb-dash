This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2025-04-16T08:59:02.153Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.flox/
  env/
    manifest.lock
    manifest.toml
  .gitignore
  env.json
.specstory/
  history/
    2025-04-14_17-51-updating-instructions-for-flox-and-envrc.md
  .what-is-this.md
app/
  api/
    sensors/
      batch/
        route.ts
      clear/
        route.ts
      metadata/
        route.ts
      route.ts
  globals.css
  layout.tsx
  page.tsx
hooks/
  use-mobile.tsx
  use-toast.ts
lib/
  config.ts
  data-service.ts
  utils.ts
public/
  placeholder-logo.svg
  placeholder.svg
scripts/
  pin-versions.js
styles/
  augment.css
  globals.css
.dockerignore
.gitignore
build.sh
CLAUDE.md
components.json
config.yaml.example
docker-compose.yml
Dockerfile
next.config.mjs
package.json
postcss.config.mjs
README.md
tailwind.config.ts
tsconfig.json

================================================================
Repository Files
================================================================

================
File: .flox/env/manifest.lock
================
{
  "lockfile-version": 1,
  "manifest": {
    "version": 1,
    "install": {
      "nodejs": {
        "pkg-path": "nodejs"
      }
    },
    "hook": {
      "on-activate": "  # Autogenerated by Flox\n\n  # Install nodejs dependencies\n  npm install\n\n  # End autogenerated by Flox\n"
    },
    "profile": {},
    "options": {
      "systems": [
        "aarch64-darwin",
        "aarch64-linux",
        "x86_64-darwin",
        "x86_64-linux"
      ],
      "allow": {
        "licenses": []
      },
      "semver": {}
    }
  },
  "packages": [
    {
      "attr_path": "nodejs",
      "broken": false,
      "derivation": "/nix/store/v4xdr255vdcghnqyvk7ih2ppvx0lapfk-nodejs-22.14.0.drv",
      "description": "Event-driven I/O framework for the V8 JavaScript engine",
      "install_id": "nodejs",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=2631b0b7abcea6e640ce31cd78ea58910d31e650",
      "name": "nodejs-22.14.0",
      "pname": "nodejs",
      "rev": "2631b0b7abcea6e640ce31cd78ea58910d31e650",
      "rev_count": 782401,
      "rev_date": "2025-04-12T13:19:24Z",
      "scrape_date": "2025-04-14T01:11:27.527343Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "22.14.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "libv8": "/nix/store/4m6xhygkx74fsd5k99nihgr7vg85f553-nodejs-22.14.0-libv8",
        "out": "/nix/store/i1v519j66jmvpqr5h382i9nanxwa5l6n-nodejs-22.14.0"
      },
      "system": "aarch64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nodejs",
      "broken": false,
      "derivation": "/nix/store/6678kk8l6dfvfawlpf8smjm0b6zinn2f-nodejs-22.14.0.drv",
      "description": "Event-driven I/O framework for the V8 JavaScript engine",
      "install_id": "nodejs",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=2631b0b7abcea6e640ce31cd78ea58910d31e650",
      "name": "nodejs-22.14.0",
      "pname": "nodejs",
      "rev": "2631b0b7abcea6e640ce31cd78ea58910d31e650",
      "rev_count": 782401,
      "rev_date": "2025-04-12T13:19:24Z",
      "scrape_date": "2025-04-14T01:28:13.241342Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "22.14.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "libv8": "/nix/store/s8407q9aa2mi2b60zk2mkjjdnv4qw87x-nodejs-22.14.0-libv8",
        "out": "/nix/store/p6183qmkyfkz5sqlv4wbw6a2nnh1r8jf-nodejs-22.14.0"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nodejs",
      "broken": false,
      "derivation": "/nix/store/zal73kvqhchl43qs2x7p5cvp57ypd4n3-nodejs-22.14.0.drv",
      "description": "Event-driven I/O framework for the V8 JavaScript engine",
      "install_id": "nodejs",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=2631b0b7abcea6e640ce31cd78ea58910d31e650",
      "name": "nodejs-22.14.0",
      "pname": "nodejs",
      "rev": "2631b0b7abcea6e640ce31cd78ea58910d31e650",
      "rev_count": 782401,
      "rev_date": "2025-04-12T13:19:24Z",
      "scrape_date": "2025-04-14T01:43:38.665121Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "22.14.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "libv8": "/nix/store/sx5pbfq09qkl6bfxcljmhf5s1z049693-nodejs-22.14.0-libv8",
        "out": "/nix/store/mxpq0x25ayiliy6938pflhqvfc1nznkl-nodejs-22.14.0"
      },
      "system": "x86_64-darwin",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "nodejs",
      "broken": false,
      "derivation": "/nix/store/2v66xkgfmdipzpwgl813n4mqgck6w3fd-nodejs-22.14.0.drv",
      "description": "Event-driven I/O framework for the V8 JavaScript engine",
      "install_id": "nodejs",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=2631b0b7abcea6e640ce31cd78ea58910d31e650",
      "name": "nodejs-22.14.0",
      "pname": "nodejs",
      "rev": "2631b0b7abcea6e640ce31cd78ea58910d31e650",
      "rev_count": 782401,
      "rev_date": "2025-04-12T13:19:24Z",
      "scrape_date": "2025-04-14T02:02:03.945028Z",
      "stabilities": [
        "unstable"
      ],
      "unfree": false,
      "version": "22.14.0",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "libv8": "/nix/store/j4w6685rkqwwl03cc8phm8xiyb2xmbnq-nodejs-22.14.0-libv8",
        "out": "/nix/store/bmakyv5ip1wc9jk155glzdw4vnnrym04-nodejs-22.14.0"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    }
  ]
}

================
File: .flox/env/manifest.toml
================
## Flox Environment Manifest -----------------------------------------
##
##   _Everything_ you need to know about the _manifest_ is here:
##
##               https://flox.dev/docs/concepts/manifest
##
## -------------------------------------------------------------------
# Flox manifest version managed by Flox CLI
version = 1


## Install Packages --------------------------------------------------
##  $ flox install gum  <- puts a package in [install] section below
##  $ flox search gum   <- search for a package
##  $ flox show gum     <- show all versions of a package
## -------------------------------------------------------------------
[install]
nodejs = { pkg-path = "nodejs" }


## Environment Variables ---------------------------------------------
##  ... available for use in the activated environment
##      as well as [hook], [profile] scripts and [services] below.
## -------------------------------------------------------------------
[vars]
# INTRO_MESSAGE = "It's gettin' Flox in here"


## Activation Hook ---------------------------------------------------
##  ... run by _bash_ shell when you run 'flox activate'.
## -------------------------------------------------------------------
[hook]
on-activate = """
  # Autogenerated by Flox

  # Install nodejs dependencies
  npm install

  # End autogenerated by Flox
"""


## Profile script ----------------------------------------------------
## ... sourced by _your shell_ when you run 'flox activate'.
## -------------------------------------------------------------------
[profile]
# common = '''
#   gum style \
#   --foreground 212 --border-foreground 212 --border double \
#   --align center --width 50 --margin "1 2" --padding "2 4" \
#     $INTRO_MESSAGE
# '''
## Shell specific profiles go here:
# bash = ...
# zsh  = ...
# fish = ...


## Services ----------------------------------------------------------
##  $ flox services start             <- Starts all services
##  $ flox services status            <- Status of running services
##  $ flox activate --start-services  <- Activates & starts all
## -------------------------------------------------------------------
[services]
# myservice.command = "python3 -m http.server"


## Other Environment Options -----------------------------------------
[options]
# Systems that environment is compatible with
systems = [
  "aarch64-darwin",
  "aarch64-linux",
  "x86_64-darwin",
  "x86_64-linux",
]
# Uncomment to disable CUDA detection.
# cuda-detection = false

================
File: .flox/.gitignore
================
run/
cache/
lib/
log/
!env/

================
File: .flox/env.json
================
{
  "name": "cosmosdb-dash",
  "version": 1
}

================
File: .specstory/history/2025-04-14_17-51-updating-instructions-for-flox-and-envrc.md
================
<!-- Generated by SpecStory -->

# Updating Instructions for Flox and .envrc (2025-04-14 10:51:49)

_**User**_

update these instructions to use flox. Alsoupdate .envrc

---

_**Assistant**_

I'll help you update the instructions to use Flox and create/update the `.envrc` file. First, let me check if there's an existing `.envrc` file.


---

Could not find file '.envrc' in the workspace.

---

I'll create a new `.envrc` file and update the README.md to include Flox instructions. Let me make these changes:

1. First, I'll create the `.envrc` file:


---

```diff
- 
+ use flox 
```

---

Now, I'll update the README.md to include Flox instructions:



---

```diff
  ## Prerequisites
  
- - Node.js 18.0 or later
+ - Flox
  - Azure Cosmos DB account
  - Git
     ```
  
- 2. **Install dependencies**
+ 2. **Set up Flox environment**
+ 
+    The project includes a `.envrc` file that will automatically set up the Flox environment. If you're using direnv, it will be loaded automatically. Otherwise, run:
+ 
+    ```bash
+    flox init
+    ```
+ 
+ 3. **Install dependencies**
  
     ```bash
-    npm install
+    flox run npm install
     # or
-    pnpm install
+    flox run pnpm install
     ```
  
- 3. **Set up environment variables**
+ 4. **Set up environment variables**
  
     Create a `.env.local` file in the root directory with the following variables:
     ```
  
- 4. **Start the development server**
+ 5. **Start the development server**
  
     ```bash
-    npm run dev
+    flox run npm run dev
     # or
-    pnpm dev
+    flox run pnpm dev
     ```
  
- 5. **Open the dashboard**
+ 6. **Open the dashboard**
  
     Navigate to [http://localhost:3000](http://localhost:3000) in your browser.
  
  ```bash
- npm run build
+ flox run npm run build
  # or
- pnpm build
+ flox run pnpm build
  ```
  
  Then start the production server:
  
  ```bash
- npm start
+ flox run npm start
  # or
- pnpm start
+ flox run pnpm start
  ```
  
  
     ```bash
-    docker build -t cosmosdb-dash .
+    flox run docker build -t cosmosdb-dash .
     ```
  
  3. **Run the container**
  
     ```bash
-    docker run -p 3000:3000 \
+    flox run docker run -p 3000:3000 \
       -e COSMOS_ENDPOINT=your_cosmos_db_endpoint \
       -e COSMOS_KEY=your_cosmos_db_key \
  
     ```bash
-    docker run -p 3000:3000 --env-file .env.production cosmosdb-dash
+    flox run docker run -p 3000:3000 --env-file .env.production cosmosdb-dash
     ```
  
  - Recharts
  - @azure/cosmos
+ - Flox
  
  ## License
```

---

I've made the following changes:

1. Created a new `.envrc` file with the basic Flox configuration
2. Updated the README.md to:
   - Replace Node.js prerequisite with Flox
   - Add Flox environment setup instructions
   - Modify all npm/pnpm commands to use `flox run`
   - Add Flox to the Development Tools section
   - Update the numbering of steps in the local development section

The changes ensure that all commands are run through Flox, which will provide a consistent development environment. The `.envrc` file is set up to automatically load the Flox environment when using direnv.

Would you like me to make any additional changes to the configuration or instructions?

---

_**User**_

 don't prefix all commands with flox - instead activate the environment

---

_**Assistant**_

I'll update the README to show how to activate the Flox environment first, rather than prefixing each command with `flox run`. I'll also fix the `.envrc` file to include the shell directive.

First, let's fix the `.envrc` file:



---

```diff
+ #!/usr/bin/env zsh
  use flox 
```

---

Now, let's update the README to show how to activate the environment first:




---

```diff
     ```bash
     flox init
+    direnv allow
     ```
  
+    This will activate the Flox environment for your current shell session.
+ 
  3. **Install dependencies**
  
     ```bash
-    flox run npm install
+    npm install
     # or
-    flox run pnpm install
+    pnpm install
     ```
  
  
     ```bash
-    flox run npm run dev
+    npm run dev
     # or
-    flox run pnpm dev
+    pnpm dev
     ```
  
  
  ```bash
- flox run npm run build
+ npm run build
  # or
- flox run pnpm build
+ pnpm build
  ```
  
  Then start the production server:
  
  ```bash
- flox run npm start
+ npm start
  # or
- flox run pnpm start
+ pnpm start
  ```
  
  
     ```bash
-    flox run docker build -t cosmosdb-dash .
+    docker build -t cosmosdb-dash .
     ```
  
  3. **Run the container**
  
     ```bash
-    flox run docker run -p 3000:3000 \
+    docker run -p 3000:3000 \
       -e COSMOS_ENDPOINT=your_cosmos_db_endpoint \
       -e COSMOS_KEY=your_cosmos_db_key \
  
     ```bash
-    flox run docker run -p 3000:3000 --env-file .env.production cosmosdb-dash
+    docker run -p 3000:3000 --env-file .env.production cosmosdb-dash
     ```
  
```

---

I've made the following changes:

1. Updated the `.envrc` file to include a shebang for zsh
2. Updated the README to:
   - Add `direnv allow` to the Flox setup instructions
   - Add a note explaining that the environment will be activated for the current shell session
   - Remove all `flox run` prefixes from commands since the environment will be activated
   - Keep the same functionality but with a cleaner command structure

The changes now show the proper way to use Flox by activating the environment once at the beginning, rather than prefixing each command. This is more efficient and follows Flox best practices.

Would you like me to make any additional changes to the configuration or instructions?

---

_**User**_

❯ direnv allow
direnv: loading ~/code/cosmosdb-dash/.envrc
direnv: using flox
environment:1120: use_flox: command not found
direnv: export +COSMOS_CONTAINER_ID +COSMOS_DATABASE_ID +COSMOS_ENDPOINT +COSMOS_KEY +GITHUB_TOKEN +GITHUB_USER +IMAGE_NAME +REGISTRY +REPOSITORY_NAME

---

_**Assistant**_

Ah, I see the issue. The `.envrc` file needs to be in shell script format since direnv uses the shell to execute it. Let me fix the `.envrc` file:



---

```diff
- #!/usr/bin/env zsh
- use flox 
+ #!/bin/sh
+ eval "$(flox activate)" 
```

---

This change:
1. Uses `/bin/sh` as the shell interpreter (which is what direnv expects)
2. Uses the proper `flox activate` command with `eval` to set up the environment

Now when you run `direnv allow`, it should properly activate the Flox environment. The error you were seeing was because `use flox` is not a valid shell command - it needed to be in the proper format for direnv to execute it.

Try running `direnv allow` again and it should work properly now. Let me know if you need any further adjustments!

---



---

================
File: .specstory/.what-is-this.md
================
# SpecStory Artifacts Directory
    
This directory is automatically created and maintained by the SpecStory extension to preserve your Cursor composer and chat history.
    
## What's Here?
    
- `.specstory/history`: Contains markdown files of your AI coding sessions
    - Each file represents a separate chat or composer session
    - Files are automatically updated as you work
- `.specstory/cursor_rules_backups`: Contains backups of the `.cursor/rules/derived-cursor-rules.mdc` file
    - Backups are automatically created each time the `.cursor/rules/derived-cursor-rules.mdc` file is updated
    - You can enable/disable the Cursor Rules feature in the SpecStory settings, it is disabled by default

## Valuable Uses
    
- Capture: Keep your context window up-to-date when starting new Chat/Composer sessions via @ references
- Search: For previous prompts and code snippets 
- Learn: Meta-analyze your patterns and learn from your past experiences
- Derive: Keep Cursor on course with your past decisions by automatically deriving Cursor rules from your AI interactions
    
## Version Control
    
We recommend keeping this directory under version control to maintain a history of your AI interactions. However, if you prefer not to version these files, you can exclude them by adding this to your `.gitignore`:
    
```
.specstory
```

We recommend not keeping the `.specstory/cursor_rules_backups` directory under version control if you are already using git to version the `.cursor/rules` directory, and committing regularly. You can exclude it by adding this to your `.gitignore`:

```
.specstory/cursor_rules_backups
```

## Searching Your Codebase
    
When searching your codebase in Cursor, search results may include your previous AI coding interactions. To focus solely on your actual code files, you can exclude the AI interaction history from search results.
    
To exclude AI interaction history:
    
1. Open the "Find in Files" search in Cursor (Cmd/Ctrl + Shift + F)
2. Navigate to the "files to exclude" section
3. Add the following pattern:
    
```
.specstory/*
```
    
This will ensure your searches only return results from your working codebase files.

## Notes

- Auto-save only works when Cursor/sqlite flushes data to disk. This results in a small delay after the AI response is complete before SpecStory can save the history.
- Auto-save does not yet work on remote WSL workspaces.

## Settings
    
You can control auto-saving behavior in Cursor:
    
1. Open Cursor → Settings → VS Code Settings (Cmd/Ctrl + ,)
2. Search for "SpecStory"
3. Find "Auto Save" setting to enable/disable
    
Auto-save occurs when changes are detected in Cursor's sqlite database, or every 2 minutes as a safety net.

================
File: app/api/sensors/batch/route.ts
================
import { NextResponse } from "next/server"
import { CosmosClient } from "@azure/cosmos"
import { getCosmosConfig } from "@/lib/config"

// Initialize the Cosmos client
let client: CosmosClient | null = null
let database: any = null
let container: any = null

// Initialize the client only once
function getCosmosClient() {
  if (!client) {
    const config = getCosmosConfig()
    console.log("Initializing CosmosDB client with endpoint:", config.endpoint)

    if (!config.endpoint || !config.key) {
      throw new Error("CosmosDB endpoint or key is missing")
    }

    client = new CosmosClient({ endpoint: config.endpoint, key: config.key })
    database = client.database(config.databaseId)
    container = database.container(config.containerId)
  }
  return { client, database, container }
}

export async function GET(request: Request) {
  try {
    const { searchParams } = new URL(request.url)
    const timestampsParam = searchParams.get("timestamps") || "{}"

    // Parse the timestamps JSON
    let lastTimestamps: Record<string, string> = {}
    try {
      lastTimestamps = JSON.parse(decodeURIComponent(timestampsParam))
    } catch (e) {
      console.error("Error parsing timestamps:", e)
    }

    console.log(`Fetching batched data with ${Object.keys(lastTimestamps).length} timestamp entries`)

    // Get the client and container
    const { container } = getCosmosClient()

    // Find the earliest timestamp across all combinations
    // This allows us to make a single query that covers all sensors/cities
    let earliestTimestamp = new Date().toISOString()

    if (Object.keys(lastTimestamps).length > 0) {
      // Find the earliest timestamp
      earliestTimestamp = Object.values(lastTimestamps).reduce((earliest, current) => {
        return current < earliest ? current : earliest
      }, Object.values(lastTimestamps)[0])
    } else {
      // If no timestamps provided, use a timestamp from 24 hours ago
      const yesterday = new Date()
      yesterday.setDate(yesterday.getDate() - 1)
      earliestTimestamp = yesterday.toISOString()
    }

    // Build a single query that gets all data since the earliest timestamp
    const querySpec = {
      query: "SELECT * FROM c WHERE c.timestamp > @timestamp ORDER BY c.timestamp ASC OFFSET 0 LIMIT 1000",
      parameters: [
        {
          name: "@timestamp",
          value: earliestTimestamp,
        },
      ],
    }

    // Execute the query
    const { resources: results } = await container.items.query(querySpec).fetchAll()

    console.log(`Found ${results.length} results in batched query`)

    // Filter the results client-side to only include data newer than each sensor/city's last timestamp
    const filteredResults = results.filter((reading: any) => {
      const key = `${reading.sensorId}:${reading.city}`
      const lastTimestamp = lastTimestamps[key]

      // Include the reading if we don't have a timestamp for this combination
      // or if the reading is newer than the last timestamp
      return !lastTimestamp || reading.timestamp > lastTimestamp
    })

    console.log(`Filtered to ${filteredResults.length} new readings`)

    return NextResponse.json({
      data: filteredResults,
    })
  } catch (error: any) {
    console.error("Error fetching batched data from CosmosDB:", error)

    // Return more detailed error information
    return NextResponse.json(
      {
        error: "Failed to fetch batched sensor data",
        message: error.message,
        details: error.toString(),
      },
      { status: 500 },
    )
  }
}

================
File: app/api/sensors/clear/route.ts
================
import { NextResponse } from "next/server"
import { CosmosClient } from "@azure/cosmos"
import { getCosmosConfig } from "@/lib/config"

// Initialize the Cosmos client
let client: CosmosClient | null = null
let database: any = null
let container: any = null

// Initialize the client only once
function getCosmosClient() {
  if (!client) {
    const config = getCosmosConfig()
    console.log("Initializing CosmosDB client with endpoint:", config.endpoint)

    if (!config.endpoint || !config.key) {
      throw new Error("CosmosDB endpoint or key is missing")
    }

    client = new CosmosClient({ endpoint: config.endpoint, key: config.key })
    database = client.database(config.databaseId)
    container = database.container(config.containerId)
  }
  return { client, database, container }
}

export async function DELETE() {
  try {
    console.log("Attempting to clear all data from the database")

    // Get the client and container
    const { container } = getCosmosClient()

    // In CosmosDB, we can't easily delete all items at once
    // We need to query for all items and delete them one by one
    // For safety, we'll limit this to a reasonable number of items

    // First, get all item IDs and partition keys
    const querySpec = {
      query: "SELECT c.id, c.city FROM c",
    }

    const { resources: items } = await container.items.query(querySpec).fetchAll()
    console.log(`Found ${items.length} items to delete`)

    // Delete each item
    let deletedCount = 0
    for (const item of items) {
      try {
        await container.item(item.id, item.city).delete()
        deletedCount++
      } catch (deleteError) {
        console.error(`Error deleting item ${item.id}:`, deleteError)
      }
    }

    console.log(`Successfully deleted ${deletedCount} items`)

    return NextResponse.json({
      success: true,
      message: `Successfully cleared ${deletedCount} items from the database`,
    })
  } catch (error: any) {
    console.error("Error clearing data from CosmosDB:", error)

    return NextResponse.json(
      {
        success: false,
        error: "Failed to clear data",
        message: error.message,
        details: error.toString(),
      },
      { status: 500 },
    )
  }
}

================
File: app/api/sensors/metadata/route.ts
================
import { NextResponse } from "next/server"
import { CosmosClient } from "@azure/cosmos"
import { getCosmosConfig } from "@/lib/config"

// Initialize the Cosmos client
let client: CosmosClient | null = null
let database: any = null
let container: any = null

// Initialize the client only once
function getCosmosClient() {
  if (!client) {
    const config = getCosmosConfig()
    console.log("Initializing CosmosDB client with endpoint:", config.endpoint)

    if (!config.endpoint || !config.key) {
      throw new Error("CosmosDB endpoint or key is missing")
    }

    client = new CosmosClient({ endpoint: config.endpoint, key: config.key })
    database = client.database(config.databaseId)
    container = database.container(config.containerId)
  }
  return { client, database, container }
}

export async function GET() {
  try {
    console.log("Fetching metadata (unique sensors and cities)")

    // Get the client and container
    const { container } = getCosmosClient()

    // Query for unique sensor IDs
    const sensorQuery = {
      query: "SELECT DISTINCT VALUE c.sensorId FROM c",
    }

    // Query for unique cities
    const cityQuery = {
      query: "SELECT DISTINCT VALUE c.city FROM c",
    }

    // Execute both queries in parallel
    const [sensorResults, cityResults] = await Promise.all([
      container.items.query(sensorQuery).fetchAll(),
      container.items.query(cityQuery).fetchAll(),
    ])

    console.log(
      `Found ${sensorResults.resources.length} unique sensors and ${cityResults.resources.length} unique cities`,
    )

    return NextResponse.json({
      sensors: sensorResults.resources,
      cities: cityResults.resources,
    })
  } catch (error: any) {
    console.error("Error fetching metadata from CosmosDB:", error)

    // Return more detailed error information
    return NextResponse.json(
      {
        error: "Failed to fetch metadata",
        message: error.message,
        details: error.toString(),
      },
      { status: 500 },
    )
  }
}

================
File: app/api/sensors/route.ts
================
import { NextResponse } from "next/server"
import { CosmosClient } from "@azure/cosmos"
import { getCosmosConfig } from "@/lib/config"

// Initialize the Cosmos client
let client: CosmosClient | null = null
let database: any = null
let container: any = null

// Initialize the client only once
function getCosmosClient() {
  if (!client) {
    const config = getCosmosConfig()
    console.log("Initializing CosmosDB client with endpoint:", config.endpoint)

    if (!config.endpoint || !config.key) {
      throw new Error("CosmosDB endpoint or key is missing")
    }

    client = new CosmosClient({ endpoint: config.endpoint, key: config.key })
    database = client.database(config.databaseId)
    container = database.container(config.containerId)
  }
  return { client, database, container }
}

export async function GET(request: Request) {
  try {
    const { searchParams } = new URL(request.url)
    const city = searchParams.get("city") || null
    const sensorId = searchParams.get("sensorId") || null
    const sinceTimestamp = searchParams.get("since") || new Date(0).toISOString()

    console.log(`Fetching data for city: ${city}, sensor: ${sensorId}, since: ${sinceTimestamp}`)

    // Get the client and container
    const { container } = getCosmosClient()

    // Build the query based on parameters
    let queryText = "SELECT * FROM c WHERE c.timestamp > @timestamp"
    const parameters: { name: string; value: string }[] = [
      {
        name: "@timestamp",
        value: sinceTimestamp,
      },
    ]

    // Add city filter if specified
    if (city) {
      queryText += " AND c.city = @city"
      parameters.push({
        name: "@city",
        value: city,
      })
    }

    // Add sensor filter if specified
    if (sensorId) {
      queryText += " AND c.sensorId = @sensorId"
      parameters.push({
        name: "@sensorId",
        value: sensorId,
      })
    }

    // Add order and limit
    queryText += " ORDER BY c.timestamp ASC OFFSET 0 LIMIT 500"

    const querySpec = {
      query: queryText,
      parameters,
    }

    // Execute the query
    const { resources: results } = await container.items.query(querySpec).fetchAll()

    console.log(`Found ${results.length} results`)

    return NextResponse.json({
      data: results,
    })
  } catch (error: any) {
    console.error("Error fetching data from CosmosDB:", error)

    // Return more detailed error information
    return NextResponse.json(
      {
        error: "Failed to fetch sensor data",
        message: error.message,
        details: error.toString(),
      },
      { status: 500 },
    )
  }
}

================
File: app/globals.css
================
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  :root {
    --background: 0 0% 100%;
    --foreground: 222.2 84% 4.9%;

    --card: 0 0% 100%;
    --card-foreground: 222.2 84% 4.9%;

    --popover: 0 0% 100%;
    --popover-foreground: 222.2 84% 4.9%;

    --primary: 222.2 47.4% 11.2%;
    --primary-foreground: 210 40% 98%;

    --secondary: 210 40% 96.1%;
    --secondary-foreground: 222.2 47.4% 11.2%;

    --muted: 210 40% 96.1%;
    --muted-foreground: 215.4 16.3% 46.9%;

    --accent: 210 40% 96.1%;
    --accent-foreground: 222.2 47.4% 11.2%;

    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 210 40% 98%;

    --border: 214.3 31.8% 91.4%;
    --input: 214.3 31.8% 91.4%;
    --ring: 222.2 84% 4.9%;

    --radius: 0.5rem;

    --chart-1: 230 100% 70%;
    --chart-2: 160 100% 70%;
    --chart-3: 340 100% 70%;
    --chart-4: 40 100% 70%;
    --chart-5: 270 100% 70%;
  }

  .dark {
    --background: 222.2 84% 4.9%;
    --foreground: 210 40% 98%;

    --card: 222.2 84% 4.9%;
    --card-foreground: 210 40% 98%;

    --popover: 222.2 84% 4.9%;
    --popover-foreground: 210 40% 98%;

    --primary: 210 40% 98%;
    --primary-foreground: 222.2 47.4% 11.2%;

    --secondary: 217.2 32.6% 17.5%;
    --secondary-foreground: 210 40% 98%;

    --muted: 217.2 32.6% 17.5%;
    --muted-foreground: 215 20.2% 65.1%;

    --accent: 217.2 32.6% 17.5%;
    --accent-foreground: 210 40% 98%;

    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 210 40% 98%;

    --border: 217.2 32.6% 17.5%;
    --input: 217.2 32.6% 17.5%;
    --ring: 212.7 26.8% 83.9%;
  }
}

@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
  }
}

================
File: app/layout.tsx
================
import type React from "react"
import type { Metadata } from "next"
import { Inter } from "next/font/google"
import "./globals.css"
import { ThemeProvider } from "@/components/theme-provider"

const inter = Inter({ subsets: ["latin"] })

export const metadata: Metadata = {
  title: "CosmosDB Sensor Dashboard",
  description: "Real-time visualization of sensor data from Azure CosmosDB",
    generator: 'v0.dev'
}

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode
}>) {
  return (
    <html lang="en" className="dark">
      <head><link rel='stylesheet' href='/styles/augment.css' /></head>
      <body className={inter.className}>
        <ThemeProvider attribute="class" defaultTheme="dark" enableSystem={false} disableTransitionOnChange>
          {children}
        </ThemeProvider>
      </body>
    </html>
  )
}


import './globals.css'

================
File: app/page.tsx
================
import type React from "react"
import { Suspense } from "react"
import Dashboard from "@/components/dashboard"
import { Loader2 } from "lucide-react"

export default function Home() {
  return (
    <main className="min-h-screen bg-black text-white p-6">
      <nav>
        <h1 className="text-4xl md:text-6xl font-bold mb-6 text-center">
          High-Scale Data Processing with Azure Cosmos DB
        </h1>
      </nav>
      <Suspense
        fallback={
          <div className="flex items-center justify-center h-[80vh]">
            <Loader2 className="h-16 w-16 animate-spin text-primary" />
            <span className="ml-4 text-3xl">Loading Dashboard...</span>
          </div>
        }
      >
        <ErrorBoundary>
          <Dashboard />
        </ErrorBoundary>
      </Suspense>
    </main>
  )
}

// Simple error boundary component
function ErrorBoundary({ children }: { children: React.ReactNode }) {
  return <div>{children}</div>
}

================
File: hooks/use-mobile.tsx
================
import * as React from "react"

const MOBILE_BREAKPOINT = 768

export function useIsMobile() {
  const [isMobile, setIsMobile] = React.useState<boolean | undefined>(undefined)

  React.useEffect(() => {
    const mql = window.matchMedia(`(max-width: ${MOBILE_BREAKPOINT - 1}px)`)
    const onChange = () => {
      setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)
    }
    mql.addEventListener("change", onChange)
    setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)
    return () => mql.removeEventListener("change", onChange)
  }, [])

  return !!isMobile
}

================
File: hooks/use-toast.ts
================
"use client"

// Inspired by react-hot-toast library
import * as React from "react"

import type {
  ToastActionElement,
  ToastProps,
} from "@/components/ui/toast"

const TOAST_LIMIT = 1
const TOAST_REMOVE_DELAY = 1000000

type ToasterToast = ToastProps & {
  id: string
  title?: React.ReactNode
  description?: React.ReactNode
  action?: ToastActionElement
}

const actionTypes = {
  ADD_TOAST: "ADD_TOAST",
  UPDATE_TOAST: "UPDATE_TOAST",
  DISMISS_TOAST: "DISMISS_TOAST",
  REMOVE_TOAST: "REMOVE_TOAST",
} as const

let count = 0

function genId() {
  count = (count + 1) % Number.MAX_SAFE_INTEGER
  return count.toString()
}

type ActionType = typeof actionTypes

type Action =
  | {
      type: ActionType["ADD_TOAST"]
      toast: ToasterToast
    }
  | {
      type: ActionType["UPDATE_TOAST"]
      toast: Partial<ToasterToast>
    }
  | {
      type: ActionType["DISMISS_TOAST"]
      toastId?: ToasterToast["id"]
    }
  | {
      type: ActionType["REMOVE_TOAST"]
      toastId?: ToasterToast["id"]
    }

interface State {
  toasts: ToasterToast[]
}

const toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()

const addToRemoveQueue = (toastId: string) => {
  if (toastTimeouts.has(toastId)) {
    return
  }

  const timeout = setTimeout(() => {
    toastTimeouts.delete(toastId)
    dispatch({
      type: "REMOVE_TOAST",
      toastId: toastId,
    })
  }, TOAST_REMOVE_DELAY)

  toastTimeouts.set(toastId, timeout)
}

export const reducer = (state: State, action: Action): State => {
  switch (action.type) {
    case "ADD_TOAST":
      return {
        ...state,
        toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),
      }

    case "UPDATE_TOAST":
      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === action.toast.id ? { ...t, ...action.toast } : t
        ),
      }

    case "DISMISS_TOAST": {
      const { toastId } = action

      // ! Side effects ! - This could be extracted into a dismissToast() action,
      // but I'll keep it here for simplicity
      if (toastId) {
        addToRemoveQueue(toastId)
      } else {
        state.toasts.forEach((toast) => {
          addToRemoveQueue(toast.id)
        })
      }

      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === toastId || toastId === undefined
            ? {
                ...t,
                open: false,
              }
            : t
        ),
      }
    }
    case "REMOVE_TOAST":
      if (action.toastId === undefined) {
        return {
          ...state,
          toasts: [],
        }
      }
      return {
        ...state,
        toasts: state.toasts.filter((t) => t.id !== action.toastId),
      }
  }
}

const listeners: Array<(state: State) => void> = []

let memoryState: State = { toasts: [] }

function dispatch(action: Action) {
  memoryState = reducer(memoryState, action)
  listeners.forEach((listener) => {
    listener(memoryState)
  })
}

type Toast = Omit<ToasterToast, "id">

function toast({ ...props }: Toast) {
  const id = genId()

  const update = (props: ToasterToast) =>
    dispatch({
      type: "UPDATE_TOAST",
      toast: { ...props, id },
    })
  const dismiss = () => dispatch({ type: "DISMISS_TOAST", toastId: id })

  dispatch({
    type: "ADD_TOAST",
    toast: {
      ...props,
      id,
      open: true,
      onOpenChange: (open) => {
        if (!open) dismiss()
      },
    },
  })

  return {
    id: id,
    dismiss,
    update,
  }
}

function useToast() {
  const [state, setState] = React.useState<State>(memoryState)

  React.useEffect(() => {
    listeners.push(setState)
    return () => {
      const index = listeners.indexOf(setState)
      if (index > -1) {
        listeners.splice(index, 1)
      }
    }
  }, [state])

  return {
    ...state,
    toast,
    dismiss: (toastId?: string) => dispatch({ type: "DISMISS_TOAST", toastId }),
  }
}

export { useToast, toast }

================
File: lib/config.ts
================
import fs from 'fs';
import yaml from 'yaml';
import path from 'path';

// Define the configuration interface
export interface CosmosConfig {
  cosmos: {
    endpoint: string;
    key: string;
    database_name: string;
    container_name: string;
    partition_key: string;
    connection?: {
      mode: string;
      max_retry_attempts: number;
      max_retry_wait_time_in_seconds: number;
      connection_timeout: number;
      enable_endpoint_discovery: boolean;
    };
    performance?: {
      enable_endpoint_discovery: boolean;
      bulk_execution: boolean;
      preferred_regions: string[];
    };
  };
  cities: Array<{
    name: string;
    latitude: number;
    longitude: number;
  }>;
  performance?: {
    throughput: number;
    autoscale: boolean;
    batch_size: number;
    max_parallel_operations: number;
    disable_indexing_during_bulk: boolean;
  };
  logging?: {
    level: string;
    log_request_units: boolean;
    log_latency: boolean;
  };
}

// Default configuration values
const defaultConfig: CosmosConfig = {
  cosmos: {
    endpoint: process.env.COSMOS_ENDPOINT || '',
    key: process.env.COSMOS_KEY || '',
    database_name: process.env.COSMOS_DATABASE_ID || 'SensorDatabase',
    container_name: process.env.COSMOS_CONTAINER_ID || 'SensorReadings',
    partition_key: '/city',
  },
  cities: [],
};

// Load configuration from YAML file
export function loadConfig(): CosmosConfig {
  try {
    // First try to load from config.yaml
    const configPath = path.resolve(process.cwd(), 'config.yaml');
    
    if (fs.existsSync(configPath)) {
      const fileContents = fs.readFileSync(configPath, 'utf8');
      const config = yaml.parse(fileContents) as CosmosConfig;
      
      // Fallback to environment variables if values are empty
      config.cosmos.endpoint = config.cosmos.endpoint || process.env.COSMOS_ENDPOINT || '';
      config.cosmos.key = config.cosmos.key || process.env.COSMOS_KEY || '';
      config.cosmos.database_name = config.cosmos.database_name || process.env.COSMOS_DATABASE_ID || 'SensorDatabase';
      config.cosmos.container_name = config.cosmos.container_name || process.env.COSMOS_CONTAINER_ID || 'SensorReadings';
      
      return config;
    }
    
    // If no config file, use environment variables
    return defaultConfig;
  } catch (error) {
    console.error('Error loading configuration:', error);
    return defaultConfig;
  }
}

// Get the Cosmos DB configuration
export function getCosmosConfig() {
  const config = loadConfig();
  return {
    endpoint: config.cosmos.endpoint,
    key: config.cosmos.key,
    databaseId: config.cosmos.database_name,
    containerId: config.cosmos.container_name,
    partitionKey: config.cosmos.partition_key,
  };
}

// Export singleton instance
export const config = loadConfig();

================
File: lib/data-service.ts
================
// Function to fetch batched sensor data with timestamps for each sensor/city combination
export async function fetchBatchedSensorData(lastTimestamps: Record<string, string>) {
  try {
    console.log("Fetching batched sensor data...")

    // Convert the lastTimestamps object to a JSON string to pass as a query parameter
    const timestampsParam = encodeURIComponent(JSON.stringify(lastTimestamps))

    const response = await fetch(`/api/sensors/batch?timestamps=${timestampsParam}`)

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      console.error("API error details:", errorData)
      throw new Error(`HTTP error! status: ${response.status}, message: ${errorData.message || "Unknown error"}`)
    }

    return await response.json()
  } catch (error) {
    console.error("Error fetching batched sensor data:", error)
    throw error
  }
}

// Function to fetch metadata (unique sensors and cities)
export async function fetchMetadata() {
  try {
    const response = await fetch("/api/sensors/metadata")

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      console.error("API error details for metadata:", errorData)
      throw new Error(`HTTP error! status: ${response.status}, message: ${errorData.message || "Unknown error"}`)
    }

    return await response.json()
  } catch (error) {
    console.error("Error fetching metadata:", error)
    throw error
  }
}

// Function to clear all data from the database
export async function clearAllData() {
  try {
    const response = await fetch("/api/sensors/clear", {
      method: "DELETE",
    })

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      console.error("API error details for clearing data:", errorData)
      throw new Error(`HTTP error! status: ${response.status}, message: ${errorData.message || "Unknown error"}`)
    }

    return await response.json()
  } catch (error) {
    console.error("Error clearing data:", error)
    throw error
  }
}

================
File: lib/utils.ts
================
import { clsx, type ClassValue } from "clsx"
import { twMerge } from "tailwind-merge"

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}

================
File: public/placeholder-logo.svg
================
<svg xmlns="http://www.w3.org/2000/svg" width="215" height="48" fill="none"><path fill="#000" d="M57.588 9.6h6L73.828 38h-5.2l-2.36-6.88h-11.36L52.548 38h-5.2l10.24-28.4Zm7.16 17.16-4.16-12.16-4.16 12.16h8.32Zm23.694-2.24c-.186-1.307-.706-2.32-1.56-3.04-.853-.72-1.866-1.08-3.04-1.08-1.68 0-2.986.613-3.92 1.84-.906 1.227-1.36 2.947-1.36 5.16s.454 3.933 1.36 5.16c.934 1.227 2.24 1.84 3.92 1.84 1.254 0 2.307-.373 3.16-1.12.854-.773 1.387-1.867 1.6-3.28l5.12.24c-.186 1.68-.733 3.147-1.64 4.4-.906 1.227-2.08 2.173-3.52 2.84-1.413.667-2.986 1-4.72 1-2.08 0-3.906-.453-5.48-1.36-1.546-.907-2.76-2.2-3.64-3.88-.853-1.68-1.28-3.627-1.28-5.84 0-2.24.427-4.187 1.28-5.84.88-1.68 2.094-2.973 3.64-3.88 1.574-.907 3.4-1.36 5.48-1.36 1.68 0 3.227.32 4.64.96 1.414.64 2.56 1.56 3.44 2.76.907 1.2 1.454 2.6 1.64 4.2l-5.12.28Zm11.486-7.72.12 3.4c.534-1.227 1.307-2.173 2.32-2.84 1.04-.693 2.267-1.04 3.68-1.04 1.494 0 2.76.387 3.8 1.16 1.067.747 1.827 1.813 2.28 3.2.507-1.44 1.294-2.52 2.36-3.24 1.094-.747 2.414-1.12 3.96-1.12 1.414 0 2.64.307 3.68.92s1.84 1.52 2.4 2.72c.56 1.2.84 2.667.84 4.4V38h-4.96V25.92c0-1.813-.293-3.187-.88-4.12-.56-.96-1.413-1.44-2.56-1.44-.906 0-1.68.213-2.32.64-.64.427-1.133 1.053-1.48 1.88-.32.827-.48 1.84-.48 3.04V38h-4.56V25.92c0-1.2-.133-2.213-.4-3.04-.24-.827-.626-1.453-1.16-1.88-.506-.427-1.133-.64-1.88-.64-.906 0-1.68.227-2.32.68-.64.427-1.133 1.053-1.48 1.88-.32.827-.48 1.827-.48 3V38h-4.96V16.8h4.48Zm26.723 10.6c0-2.24.427-4.187 1.28-5.84.854-1.68 2.067-2.973 3.64-3.88 1.574-.907 3.4-1.36 5.48-1.36 1.84 0 3.494.413 4.96 1.24 1.467.827 2.64 2.08 3.52 3.76.88 1.653 1.347 3.693 1.4 6.12v1.32h-15.08c.107 1.813.614 3.227 1.52 4.24.907.987 2.134 1.48 3.68 1.48.987 0 1.88-.253 2.68-.76a4.803 4.803 0 0 0 1.84-2.2l5.08.36c-.64 2.027-1.84 3.64-3.6 4.84-1.733 1.173-3.733 1.76-6 1.76-2.08 0-3.906-.453-5.48-1.36-1.573-.907-2.786-2.2-3.64-3.88-.853-1.68-1.28-3.627-1.28-5.84Zm15.16-2.04c-.213-1.733-.76-3.013-1.64-3.84-.853-.827-1.893-1.24-3.12-1.24-1.44 0-2.6.453-3.48 1.36-.88.88-1.44 2.12-1.68 3.72h9.92ZM163.139 9.6V38h-5.04V9.6h5.04Zm8.322 7.2.24 5.88-.64-.36c.32-2.053 1.094-3.56 2.32-4.52 1.254-.987 2.787-1.48 4.6-1.48 2.32 0 4.107.733 5.36 2.2 1.254 1.44 1.88 3.387 1.88 5.84V38h-4.96V25.92c0-1.253-.12-2.28-.36-3.08-.24-.8-.64-1.413-1.2-1.84-.533-.427-1.253-.64-2.16-.64-1.44 0-2.573.48-3.4 1.44-.8.933-1.2 2.307-1.2 4.12V38h-4.96V16.8h4.48Zm30.003 7.72c-.186-1.307-.706-2.32-1.56-3.04-.853-.72-1.866-1.08-3.04-1.08-1.68 0-2.986.613-3.92 1.84-.906 1.227-1.36 2.947-1.36 5.16s.454 3.933 1.36 5.16c.934 1.227 2.24 1.84 3.92 1.84 1.254 0 2.307-.373 3.16-1.12.854-.773 1.387-1.867 1.6-3.28l5.12.24c-.186 1.68-.733 3.147-1.64 4.4-.906 1.227-2.08 2.173-3.52 2.84-1.413.667-2.986 1-4.72 1-2.08 0-3.906-.453-5.48-1.36-1.546-.907-2.76-2.2-3.64-3.88-.853-1.68-1.28-3.627-1.28-5.84 0-2.24.427-4.187 1.28-5.84.88-1.68 2.094-2.973 3.64-3.88 1.574-.907 3.4-1.36 5.48-1.36 1.68 0 3.227.32 4.64.96 1.414.64 2.56 1.56 3.44 2.76.907 1.2 1.454 2.6 1.64 4.2l-5.12.28Zm11.443 8.16V38h-5.6v-5.32h5.6Z"/><path fill="#171717" fill-rule="evenodd" d="m7.839 40.783 16.03-28.054L20 6 0 40.783h7.839Zm8.214 0H40L27.99 19.894l-4.02 7.032 3.976 6.914H20.02l-3.967 6.943Z" clip-rule="evenodd"/></svg>

================
File: public/placeholder.svg
================
<svg xmlns="http://www.w3.org/2000/svg" width="1200" height="1200" fill="none"><rect width="1200" height="1200" fill="#EAEAEA" rx="3"/><g opacity=".5"><g opacity=".5"><path fill="#FAFAFA" d="M600.709 736.5c-75.454 0-136.621-61.167-136.621-136.62 0-75.454 61.167-136.621 136.621-136.621 75.453 0 136.62 61.167 136.62 136.621 0 75.453-61.167 136.62-136.62 136.62Z"/><path stroke="#C9C9C9" stroke-width="2.418" d="M600.709 736.5c-75.454 0-136.621-61.167-136.621-136.62 0-75.454 61.167-136.621 136.621-136.621 75.453 0 136.62 61.167 136.62 136.621 0 75.453-61.167 136.62-136.62 136.62Z"/></g><path stroke="url(#a)" stroke-width="2.418" d="M0-1.209h553.581" transform="scale(1 -1) rotate(45 1163.11 91.165)"/><path stroke="url(#b)" stroke-width="2.418" d="M404.846 598.671h391.726"/><path stroke="url(#c)" stroke-width="2.418" d="M599.5 795.742V404.017"/><path stroke="url(#d)" stroke-width="2.418" d="m795.717 796.597-391.441-391.44"/><path fill="#fff" d="M600.709 656.704c-31.384 0-56.825-25.441-56.825-56.824 0-31.384 25.441-56.825 56.825-56.825 31.383 0 56.824 25.441 56.824 56.825 0 31.383-25.441 56.824-56.824 56.824Z"/><g clip-path="url(#e)"><path fill="#666" fill-rule="evenodd" d="M616.426 586.58h-31.434v16.176l3.553-3.554.531-.531h9.068l.074-.074 8.463-8.463h2.565l7.18 7.181V586.58Zm-15.715 14.654 3.698 3.699 1.283 1.282-2.565 2.565-1.282-1.283-5.2-5.199h-6.066l-5.514 5.514-.073.073v2.876a2.418 2.418 0 0 0 2.418 2.418h26.598a2.418 2.418 0 0 0 2.418-2.418v-8.317l-8.463-8.463-7.181 7.181-.071.072Zm-19.347 5.442v4.085a6.045 6.045 0 0 0 6.046 6.045h26.598a6.044 6.044 0 0 0 6.045-6.045v-7.108l1.356-1.355-1.282-1.283-.074-.073v-17.989h-38.689v23.43l-.146.146.146.147Z" clip-rule="evenodd"/></g><path stroke="#C9C9C9" stroke-width="2.418" d="M600.709 656.704c-31.384 0-56.825-25.441-56.825-56.824 0-31.384 25.441-56.825 56.825-56.825 31.383 0 56.824 25.441 56.824 56.825 0 31.383-25.441 56.824-56.824 56.824Z"/></g><defs><linearGradient id="a" x1="554.061" x2="-.48" y1=".083" y2=".087" gradientUnits="userSpaceOnUse"><stop stop-color="#C9C9C9" stop-opacity="0"/><stop offset=".208" stop-color="#C9C9C9"/><stop offset=".792" stop-color="#C9C9C9"/><stop offset="1" stop-color="#C9C9C9" stop-opacity="0"/></linearGradient><linearGradient id="b" x1="796.912" x2="404.507" y1="599.963" y2="599.965" gradientUnits="userSpaceOnUse"><stop stop-color="#C9C9C9" stop-opacity="0"/><stop offset=".208" stop-color="#C9C9C9"/><stop offset=".792" stop-color="#C9C9C9"/><stop offset="1" stop-color="#C9C9C9" stop-opacity="0"/></linearGradient><linearGradient id="c" x1="600.792" x2="600.794" y1="403.677" y2="796.082" gradientUnits="userSpaceOnUse"><stop stop-color="#C9C9C9" stop-opacity="0"/><stop offset=".208" stop-color="#C9C9C9"/><stop offset=".792" stop-color="#C9C9C9"/><stop offset="1" stop-color="#C9C9C9" stop-opacity="0"/></linearGradient><linearGradient id="d" x1="404.85" x2="796.972" y1="403.903" y2="796.02" gradientUnits="userSpaceOnUse"><stop stop-color="#C9C9C9" stop-opacity="0"/><stop offset=".208" stop-color="#C9C9C9"/><stop offset=".792" stop-color="#C9C9C9"/><stop offset="1" stop-color="#C9C9C9" stop-opacity="0"/></linearGradient><clipPath id="e"><path fill="#fff" d="M581.364 580.535h38.689v38.689h-38.689z"/></clipPath></defs></svg>

================
File: scripts/pin-versions.js
================
#!/usr/bin/env node

const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

// Path to package.json
const packageJsonPath = path.resolve(process.cwd(), 'package.json');

// Function to get latest version of a package
function getLatestVersion(packageName) {
  try {
    const output = execSync(`npm view ${packageName} version`, { encoding: 'utf8' });
    return output.trim();
  } catch (error) {
    console.error(`Error getting version for ${packageName}:`, error.message);
    return null;
  }
}

// Main function
async function pinVersions() {
  console.log('📌 Pinning package versions...');
  
  // Read package.json
  const packageJson = JSON.parse(fs.readFileSync(packageJsonPath, 'utf8'));
  
  // Update dependencies
  await updateDependencies(packageJson.dependencies);
  await updateDependencies(packageJson.devDependencies);
  
  // Write updated package.json
  fs.writeFileSync(packageJsonPath, JSON.stringify(packageJson, null, 2));
  
  console.log('✅ Done pinning versions. To install the pinned versions, run:');
  console.log('   npm install --legacy-peer-deps');
  console.log('   or');
  console.log('   pnpm install');
}

// Function to update dependencies object
async function updateDependencies(deps) {
  if (!deps) return;
  
  for (const [name, version] of Object.entries(deps)) {
    if (version === 'latest') {
      const latestVersion = getLatestVersion(name);
      if (latestVersion) {
        deps[name] = latestVersion;
        console.log(`${name}: latest → ${latestVersion}`);
      }
    } else if (version.startsWith('~') || version.startsWith('^')) {
      // For packages with range specifiers, get the exact version
      const packageName = name.replace(/^@/, '').replace(/\//g, '%2F');
      try {
        const exactVersion = version.substring(1);
        deps[name] = exactVersion;
        console.log(`${name}: ${version} → ${exactVersion}`);
      } catch (error) {
        console.error(`Error processing ${name}:`, error.message);
      }
    }
  }
}

// Run the script
pinVersions().catch(error => {
  console.error('Error:', error);
  process.exit(1);
});

================
File: styles/augment.css
================
nav {
    display: flex;
    align-items: center;
    justify-content: center;
}

================
File: styles/globals.css
================
@tailwind base;
@tailwind components;
@tailwind utilities;

body {
  font-family: Arial, Helvetica, sans-serif;
}

@layer utilities {
  .text-balance {
    text-wrap: balance;
  }
}

@layer base {
  :root {
    --background: 0 0% 100%;
    --foreground: 0 0% 3.9%;
    --card: 0 0% 100%;
    --card-foreground: 0 0% 3.9%;
    --popover: 0 0% 100%;
    --popover-foreground: 0 0% 3.9%;
    --primary: 0 0% 9%;
    --primary-foreground: 0 0% 98%;
    --secondary: 0 0% 96.1%;
    --secondary-foreground: 0 0% 9%;
    --muted: 0 0% 96.1%;
    --muted-foreground: 0 0% 45.1%;
    --accent: 0 0% 96.1%;
    --accent-foreground: 0 0% 9%;
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 89.8%;
    --input: 0 0% 89.8%;
    --ring: 0 0% 3.9%;
    --chart-1: 12 76% 61%;
    --chart-2: 173 58% 39%;
    --chart-3: 197 37% 24%;
    --chart-4: 43 74% 66%;
    --chart-5: 27 87% 67%;
    --radius: 0.5rem;
    --sidebar-background: 0 0% 98%;
    --sidebar-foreground: 240 5.3% 26.1%;
    --sidebar-primary: 240 5.9% 10%;
    --sidebar-primary-foreground: 0 0% 98%;
    --sidebar-accent: 240 4.8% 95.9%;
    --sidebar-accent-foreground: 240 5.9% 10%;
    --sidebar-border: 220 13% 91%;
    --sidebar-ring: 217.2 91.2% 59.8%;
  }
  .dark {
    --background: 0 0% 3.9%;
    --foreground: 0 0% 98%;
    --card: 0 0% 3.9%;
    --card-foreground: 0 0% 98%;
    --popover: 0 0% 3.9%;
    --popover-foreground: 0 0% 98%;
    --primary: 0 0% 98%;
    --primary-foreground: 0 0% 9%;
    --secondary: 0 0% 14.9%;
    --secondary-foreground: 0 0% 98%;
    --muted: 0 0% 14.9%;
    --muted-foreground: 0 0% 63.9%;
    --accent: 0 0% 14.9%;
    --accent-foreground: 0 0% 98%;
    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 0 0% 98%;
    --border: 0 0% 14.9%;
    --input: 0 0% 14.9%;
    --ring: 0 0% 83.1%;
    --chart-1: 220 70% 50%;
    --chart-2: 160 60% 45%;
    --chart-3: 30 80% 55%;
    --chart-4: 280 65% 60%;
    --chart-5: 340 75% 55%;
    --sidebar-background: 240 5.9% 10%;
    --sidebar-foreground: 240 4.8% 95.9%;
    --sidebar-primary: 224.3 76.3% 48%;
    --sidebar-primary-foreground: 0 0% 100%;
    --sidebar-accent: 240 3.7% 15.9%;
    --sidebar-accent-foreground: 240 4.8% 95.9%;
    --sidebar-border: 240 3.7% 15.9%;
    --sidebar-ring: 217.2 91.2% 59.8%;
  }
}

@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
  }
}

================
File: .dockerignore
================
# Include node_modules in .dockerignore
node_modules
npm-debug.log
.next
out
build
.git
.gitignore
README.md

# Environment files
.env
.env.local
.env.development
.env.production

# Include .env.example for documentation purposes
!.env.example

================
File: .gitignore
================
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules

# next.js
/.next/
/out/

# production
/build

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts

config.yaml

================
File: build.sh
================
#!/bin/bash

# Exit on error, undefined variables, and pipe failures
set -euo pipefail
trap 'echo "Error on line $LINENO"' ERR

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Logging functions
log() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[WARN]${NC} $1" >&2
}

error() {
    echo -e "${RED}[ERROR]${NC} $1" >&2
    exit 1
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

# Configuration with defaults
PLATFORMS="${PLATFORMS:-linux/amd64,linux/arm64}"
DOCKERFILE="${DOCKERFILE:-Dockerfile}"
BUILDER_NAME="${BUILDER_NAME:-multiarch-builder}"
REGISTRY="${REGISTRY:-ghcr.io}"
VERSION_TAG="${VERSION_TAG:-$(date +"%y%m%d%H%M")}"
SKIP_PUSH="${SKIP_PUSH:-false}"
BUILD_CACHE="${BUILD_CACHE:-true}"
REQUIRE_LOGIN="${REQUIRE_LOGIN:-true}"
GITHUB_USER="${GITHUB_USER:-$(git config user.name || echo "GITHUB_USER_NOT_SET")}"

# If REPOSITORY_NAME is not set, exit
if [ -z "${REPOSITORY_NAME:-}" ]; then
    error "REPOSITORY_NAME is not set"
fi

# If IMAGE_NAME is not set, exit
if [ -z "${IMAGE_NAME:-}" ]; then
    error "IMAGE_NAME is not set"
fi

cleanup() {
    log "Cleaning up temporary resources..."
    if [ -n "${BUILDER_NAME:-}" ]; then
        docker buildx rm "$BUILDER_NAME" >/dev/null 2>&1 || true
    fi
}

check_docker_login() {
    log "Checking if GITHUB_TOKEN and GITHUB_USER are set"
    if [ -z "${GITHUB_TOKEN:-}" ]; then
        error "GITHUB_TOKEN is not set"
    fi
    if [ -z "${GITHUB_USER:-}" ]; then
        error "GITHUB_USER is not set"
    fi

    log "Logging in to Docker registry..."
    if echo "$GITHUB_TOKEN" | docker login "$REGISTRY" --username "$GITHUB_USER" --password-stdin; then
        log "Successfully logged in to Docker registry"
    else
        error "Failed to log in to Docker registry"
    fi
}

validate_requirements() {
    local requirements=(
        "docker:Docker is required but not installed"
        "git:Git is required but not installed"
    )

    for req in "${requirements[@]}"; do
        local cmd="${req%%:*}"
        local msg="${req#*:}"
        if ! command -v "$cmd" &> /dev/null; then
            error "$msg"
        fi
    done

    # Check if dockerfile exists
    if [ ! -f "$DOCKERFILE" ]; then
        error "Dockerfile not found at $DOCKERFILE"
    fi

    # Check docker daemon is running
    if ! docker info >/dev/null 2>&1; then
        error "Docker daemon is not running"
    fi

    # Check buildx support
    if ! docker buildx version >/dev/null 2>&1; then
        error "Docker buildx support is required. Please ensure:
        1. Docker Desktop is installed and running
        2. Enable experimental features:
           - Open Docker Desktop
           - Go to Settings/Preferences > Docker Engine
           - Ensure experimental features are enabled
        3. Restart Docker Desktop"
    fi
}

setup_builder() {
    log "Setting up buildx builder..."
    
    # Check if builder already exists
    if docker buildx inspect "$BUILDER_NAME" >/dev/null 2>&1; then
        # Check if the builder is working by listing the nodes
        if docker buildx inspect --bootstrap "$BUILDER_NAME" | grep -q "Status: running"; then
            log "Using existing builder instance '$BUILDER_NAME'"
            docker buildx use "$BUILDER_NAME"
            return 0
        else
            warn "Existing builder instance is not running properly, recreating it"
            docker buildx rm "$BUILDER_NAME" >/dev/null 2>&1
        fi
    fi
    
    # Create new builder if needed
    log "Creating new builder instance '$BUILDER_NAME'"
    docker buildx create --name "$BUILDER_NAME" \
        --driver docker-container \
        --bootstrap || error "Failed to create buildx builder"
    docker buildx use "$BUILDER_NAME"
}

generate_tags() {
    local base_tag="$REGISTRY/$REPOSITORY_NAME/$IMAGE_NAME"
    local tags=()

    # Add version tag
    tags+=("$base_tag:$VERSION_TAG")
    
    # Add latest tag
    tags+=("$base_tag:latest")
    
    # If in git repo, add git commit hash tag
    if git rev-parse --git-dir > /dev/null 2>&1; then
        local git_hash
        git_hash=$(git rev-parse --short HEAD)
        tags+=("$base_tag:$git_hash")
    fi

    # Convert tags array to --tag arguments for docker buildx
    local tag_args=""
    for tag in "${tags[@]}"; do
        tag_args="$tag_args --tag $tag"
    done
    echo "$tag_args"
}

build_and_push_images() {
    local platforms="$1"
    local tag_args
    tag_args=$(generate_tags)
    
    log "Building for platforms: $platforms"
    
    # Create the build_args array
    local build_args=(
        --platform "$platforms"
        --file "$DOCKERFILE"
    )

    # Add tags to build_args (splitting the string into separate arguments)
    for tag_arg in $tag_args; do
        build_args+=("$tag_arg")
    done

    # Add cache settings
    if [ "$BUILD_CACHE" = "true" ]; then
        build_args+=(--cache-from "type=registry,ref=$REGISTRY/$REPOSITORY_NAME/$IMAGE_NAME:buildcache")
        build_args+=(--cache-to "type=registry,ref=$REGISTRY/$REPOSITORY_NAME/$IMAGE_NAME:buildcache,mode=max")
    fi

    # Add push flag if not skipping
    if [ "$SKIP_PUSH" = "false" ]; then
        build_args+=(--push)
        check_docker_login
    else
        build_args+=(--load)
    fi

    # Execute build (add the path argument ".")
    if ! docker buildx build "${build_args[@]}" .; then
        error "Build failed for $platforms"
    fi
    
    success "Successfully built images for $platforms"
}

print_usage() {
    log "Environment variables that can be set:"
    echo "  IMAGE_NAME     : Name of the image (default: derived from directory name)"
    echo "  REPOSITORY_NAME: Name of the repository (default: derived from directory name)"
    echo "  PLATFORMS      : Target platforms (default: linux/amd64,linux/arm64)"
    echo "  DOCKERFILE     : Path to Dockerfile (default: ./Dockerfile)"
    echo "  VERSION_TAG    : Version tag (default: YYMMDDHHMM)"
    echo "  REGISTRY       : Docker registry (default: docker.io)"
    echo "  SKIP_PUSH      : Skip pushing to registry (default: false)"
    echo "  BUILD_CACHE    : Use build cache (default: true)"
    echo "  REQUIRE_LOGIN  : Require Docker registry login (default: false)"
}

main() {
    trap cleanup EXIT
    
    if [ "${1:-}" = "--help" ]; then
        print_usage
        exit 0
    fi

    log "Starting build process..."
    validate_requirements
    
    setup_builder
    build_and_push_images "$PLATFORMS"
    
    success "Build completed successfully"
    
    # Pull the latest image after successful build
    if [ "$SKIP_PUSH" = "false" ]; then
        log "Pulling latest image..."
        docker pull "$REGISTRY/$REPOSITORY_NAME/$IMAGE_NAME:latest" || warn "Failed to pull latest image"
    fi
    
    log "You can now pull and run the image with:"
    log "docker pull $REGISTRY/$REPOSITORY_NAME/$IMAGE_NAME:$VERSION_TAG"
    log "docker pull $REGISTRY/$REPOSITORY_NAME/$IMAGE_NAME:latest"
}

# Execute main function
main "$@"

================
File: CLAUDE.md
================
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Build/Test Commands
- `npm run dev` - Start local development server
- `npm run build` - Build production version
- `npm run start` - Start production server
- `npm run lint` - Run ESLint for code linting
- `npm install:clean` - Clean install dependencies

## Code Style Guidelines
- **Imports**: Group related imports; React imports first, then external libraries, followed by project imports with @/ aliases
- **Types**: Use TypeScript interfaces for object shapes (see lib/config.ts for examples)
- **Error Handling**: Use try/catch with specific error types, log errors, and propagate with context
- **Naming**: Use camelCase for variables/functions, PascalCase for components/interfaces, ALL_CAPS for constants
- **Component Structure**: React components export default, client components start with "use client" directive
- **File Structure**: Keep related functionality together, UI in components/, API routes in app/api/
- **Formatting**: Use 2-space indentation, semicolons, single quotes where possible

## Cosmos DB Interaction
Access Cosmos DB via the data-service.ts abstraction layer. Handle connections carefully and always include error handling.

================
File: components.json
================
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "default",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "app/globals.css",
    "baseColor": "neutral",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  },
  "iconLibrary": "lucide"
}

================
File: config.yaml.example
================
# Azure Cosmos DB Configuration Template
# Replace placeholder values with your actual configuration

cosmos:
  # Azure Cosmos DB endpoint URL
  endpoint: ""

  # Primary key for authentication
  key: ""

  # Database name
  database_name: "SensorDatabase"

  # Container name for sensor data
  container_name: "SensorReadings"

  # Partition key path (must include the leading slash)
  partition_key: "/city"

  # Connection settings
  connection:
    # Connection mode: "Gateway" or "Direct"
    mode: "Gateway"

    # Maximum number of retry attempts for operations
    max_retry_attempts: 9

    # Maximum retry wait time in seconds
    max_retry_wait_time_in_seconds: 30

    # Connection timeout in seconds
    connection_timeout: 60

    # Whether to enable endpoint discovery for multi-region accounts
    enable_endpoint_discovery: true

# Cities configuration
cities:
  - name: Amsterdam
    latitude: 52.373080
    longitude: 4.892453
  - name: Berlin
    latitude: 52.510885
    longitude: 13.398937
  - name: London
    latitude: 51.507446
    longitude: -0.127765
  - name: New York
    latitude: 40.712728
    longitude: -74.006015
  - name: Tokyo
    latitude: 35.676860
    longitude: 139.763895

# Performance settings
performance:
  # Initial throughput in Request Units per second (RU/s)
  throughput: 10000

  # Whether to use autoscale throughput
  autoscale: true

  # Batch size for bulk operations
  batch_size: 1000

# Logging settings
logging:
  # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  level: "INFO"

================
File: docker-compose.yml
================
version: '3'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
    env_file:
      - .env.production
    restart: unless-stopped

================
File: Dockerfile
================
FROM node:20-alpine AS base

# Install dependencies only when needed
FROM base AS deps
WORKDIR /app

# Copy package files
COPY package.json pnpm-lock.yaml* ./
RUN npm install -g pnpm && pnpm install

# Rebuild the source code only when needed
FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .

# Next.js collects completely anonymous telemetry data about general usage.
# Learn more here: https://nextjs.org/telemetry
# Uncomment the following line in case you want to disable telemetry during the build.
ENV NEXT_TELEMETRY_DISABLED 1

RUN npm run build

# Production image, copy all the files and run next
FROM base AS runner
WORKDIR /app

ENV NODE_ENV production
ENV NEXT_TELEMETRY_DISABLED 1

RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

COPY --from=builder /app/public ./public

# Set the correct permission for prerender cache
RUN mkdir .next
RUN chown nextjs:nodejs .next

# Automatically leverage output traces to reduce image size
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs

EXPOSE 3000

ENV PORT 3000
# set hostname to localhost
ENV HOSTNAME "0.0.0.0"

# server.js is created by next build from the standalone output
# https://nextjs.org/docs/pages/api-reference/next-config-js/output
CMD ["node", "server.js"]

================
File: next.config.mjs
================
/** @type {import('next').NextConfig} */
const nextConfig = {
  eslint: {
    ignoreDuringBuilds: true,
  },
  typescript: {
    ignoreBuildErrors: true,
  },
  images: {
    unoptimized: true,
  },
  output: 'standalone',
}

export default nextConfig

================
File: package.json
================
{
  "name": "cosmosdb-dashboard",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "install:clean": "npm install --legacy-peer-deps",
    "update": "npx npm-check-updates -u && npm install --legacy-peer-deps",
    "pin-versions": "npx npm-check-updates -u && node scripts/pin-versions.js"
  },
  "packageManager": "pnpm@8.15.6",
  "engines": {
    "node": ">=18.0.0"
  },
  "dependencies": {
    "@azure/cosmos": "4.3.0",
    "@hookform/resolvers": "5.0.1",
    "@radix-ui/react-accordion": "1.2.4",
    "@radix-ui/react-alert-dialog": "1.1.7",
    "@radix-ui/react-aspect-ratio": "1.1.3",
    "@radix-ui/react-avatar": "1.1.4",
    "@radix-ui/react-checkbox": "1.1.5",
    "@radix-ui/react-collapsible": "1.1.4",
    "@radix-ui/react-context-menu": "2.2.7",
    "@radix-ui/react-dialog": "1.1.7",
    "@radix-ui/react-dropdown-menu": "2.1.7",
    "@radix-ui/react-hover-card": "1.1.7",
    "@radix-ui/react-label": "2.1.3",
    "@radix-ui/react-menubar": "1.1.7",
    "@radix-ui/react-navigation-menu": "1.2.6",
    "@radix-ui/react-popover": "1.1.7",
    "@radix-ui/react-progress": "1.1.3",
    "@radix-ui/react-radio-group": "1.2.4",
    "@radix-ui/react-scroll-area": "1.2.4",
    "@radix-ui/react-select": "2.1.7",
    "@radix-ui/react-separator": "1.1.3",
    "@radix-ui/react-slider": "1.2.4",
    "@radix-ui/react-slot": "1.2.0",
    "@radix-ui/react-switch": "1.1.4",
    "@radix-ui/react-tabs": "1.1.4",
    "@radix-ui/react-toast": "1.2.7",
    "@radix-ui/react-toggle": "1.1.3",
    "@radix-ui/react-toggle-group": "1.1.3",
    "@radix-ui/react-tooltip": "1.2.0",
    "class-variance-authority": "0.7.1",
    "clsx": "2.1.1",
    "cmdk": "1.1.1",
    "date-fns": "4.1.0",
    "embla-carousel-react": "8.6.0",
    "input-otp": "1.4.2",
    "lucide-react": "0.488.0",
    "next": "15.3.0",
    "next-themes": "0.4.6",
    "react": "19.1.0",
    "react-day-picker": "9.6.7",
    "react-dom": "19.1.0",
    "react-hook-form": "7.55.0",
    "react-resizable-panels": "2.1.7",
    "recharts": "2.15.2",
    "sonner": "2.0.3",
    "tailwind-merge": "3.2.0",
    "tailwindcss-animate": "1.0.7",
    "vaul": "1.1.2",
    "yaml": "2.7.1",
    "zod": "3.24.2"
  },
  "devDependencies": {
    "autoprefixer": "10.4.16",
    "@types/node": "22.14.1",
    "@types/react": "19.1.2",
    "@types/react-dom": "19.1.2",
    "npm-check-updates": "17.1.18",
    "postcss": "8.4.31",
    "tailwindcss": "3.3.5",
    "typescript": "5.8.3"
  }
}

================
File: postcss.config.mjs
================
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};

export default config;

================
File: README.md
================
# Cosmos DB Dashboard

A real-time dashboard for visualizing sensor data from Azure Cosmos DB.

## Features

- Real-time sensor data visualization
- Multi-city data comparison
- Interactive charts and tables
- Responsive design

## Prerequisites

- Node.js 18.0 or later (with npm or pnpm)
- Azure Cosmos DB account
- Git

## Getting Started

### Local Development

1. **Clone the repository**

   ```bash
   git clone https://github.com/your-username/cosmosdb-dash.git
   cd cosmosdb-dash
   ```

2. **Install dependencies**

   ```bash
   # Option 1: Using npm (with legacy peer deps to resolve conflicts)
   npm run install:clean
   
   # Option 2: Using pnpm (recommended, faster)
   pnpm install
   ```

3. **Set up configuration**

   You can configure the application using either a YAML configuration file or environment variables:

   **Option 1: Using config.yaml (recommended for complete configuration)**

   ```bash
   # Copy the example configuration file
   cp config.yaml.example config.yaml
   
   # Edit the file to add your Azure Cosmos DB credentials and settings
   nano config.yaml  # or use your preferred editor
   ```

   **Option 2: Using environment variables (quickest setup)**

   Create a `.env.local` file in the root directory:

   ```bash
   # Create .env.local file
   cat > .env.local << EOL
   COSMOS_ENDPOINT=your_cosmos_db_endpoint
   COSMOS_KEY=your_cosmos_db_key
   COSMOS_DATABASE_ID=SensorDatabase
   COSMOS_CONTAINER_ID=SensorReadings
   EOL
   ```

4. **Start the development server**

   ```bash
   npm run dev
   # or
   pnpm dev
   ```

5. **Access the dashboard**

   Open [http://localhost:3000](http://localhost:3000) in your browser.

   > Note: The dashboard will automatically attempt to connect to your Cosmos DB. If the connection fails, the dashboard will display mock data for demonstration purposes.

### Production Build

To create an optimized production build:

```bash
npm run build
# or
pnpm build
```

Then start the production server:

```bash
npm start
# or
pnpm start
```

## Docker Deployment

You can run the application in Docker using either a local build or Docker Compose.

### Quick Start with Docker Compose

1. **Set up environment variables**

   Create a `.env.production` file with your Cosmos DB credentials:

   ```bash
   cat > .env.production << EOL
   COSMOS_ENDPOINT=your_cosmos_db_endpoint
   COSMOS_KEY=your_cosmos_db_key
   COSMOS_DATABASE_ID=SensorDatabase
   COSMOS_CONTAINER_ID=SensorReadings
   EOL
   ```

2. **Start with Docker Compose**

   ```bash
   docker-compose up
   ```

   This will build and start the container, with the dashboard available at [http://localhost:3000](http://localhost:3000).

### Manual Docker Build and Run

1. **Build the image locally**

   ```bash
   docker build -t cosmosdb-dash .
   ```

2. **Run the container**

   **Option 1: Using environment variables**

   ```bash
   docker run -p 3000:3000 \
     -e COSMOS_ENDPOINT=your_cosmos_db_endpoint \
     -e COSMOS_KEY=your_cosmos_db_key \
     -e COSMOS_DATABASE_ID=SensorDatabase \
     -e COSMOS_CONTAINER_ID=SensorReadings \
     cosmosdb-dash
   ```

   **Option 2: Using mounted config file**

   ```bash
   # Ensure you've created and configured your config.yaml file first
   docker run -p 3000:3000 \
     -v $(pwd)/config.yaml:/app/config.yaml \
     cosmosdb-dash
   ```

### Publishing a Multi-Platform Image (Advanced)

The project includes a build script for creating and publishing multi-architecture Docker images:

```bash
# Make the script executable
chmod +x build.sh

# Set required environment variables
export REPOSITORY_NAME=your-github-username
export IMAGE_NAME=cosmosdb-dashboard
export GITHUB_TOKEN=your_github_token
export GITHUB_USER=your_github_username

# Run the build script
./build.sh
```

This will build and push the image to GitHub Container Registry (ghcr.io).

## Configuration

The application can be configured using either a YAML configuration file or environment variables.

### Configuration File (config.yaml)

The configuration file supports more detailed settings than environment variables. Sample settings:

```yaml
cosmos:
  endpoint: "your_cosmos_endpoint"
  key: "your_cosmos_key"
  database_name: "SensorDatabase"
  container_name: "SensorReadings"
  partition_key: "/city"
  
  connection:
    mode: "Gateway"
    max_retry_attempts: 9
    connection_timeout: 60
```

See `config.yaml.example` for a complete example.

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `COSMOS_ENDPOINT` | Your Azure Cosmos DB endpoint URL | (Required) |
| `COSMOS_KEY` | Your Azure Cosmos DB access key | (Required) |
| `COSMOS_DATABASE_ID` | The Cosmos DB database ID | `SensorDatabase` |
| `COSMOS_CONTAINER_ID` | The Cosmos DB container ID | `SensorReadings` |

## Development Tools

- Next.js 15.3.0 
- React 19.1.0
- TypeScript 5.8.3
- Tailwind CSS 3.3.5
- Recharts 2.15.2
- @azure/cosmos 4.3.0
- Flox

## License

MIT

================
File: tailwind.config.ts
================
import type { Config } from "tailwindcss"

const config = {
  darkMode: ["class"],
  content: [
    "./pages/**/*.{ts,tsx}",
    "./components/**/*.{ts,tsx}",
    "./app/**/*.{ts,tsx}",
    "./src/**/*.{ts,tsx}",
    "*.{js,ts,jsx,tsx,mdx}",
  ],
  prefix: "",
  theme: {
    container: {
      center: true,
      padding: "2rem",
      screens: {
        "2xl": "1400px",
      },
    },
    extend: {
      colors: {
        border: "hsl(var(--border))",
        input: "hsl(var(--input))",
        ring: "hsl(var(--ring))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
        primary: {
          DEFAULT: "hsl(var(--primary))",
          foreground: "hsl(var(--primary-foreground))",
        },
        secondary: {
          DEFAULT: "hsl(var(--secondary))",
          foreground: "hsl(var(--secondary-foreground))",
        },
        destructive: {
          DEFAULT: "hsl(var(--destructive))",
          foreground: "hsl(var(--destructive-foreground))",
        },
        muted: {
          DEFAULT: "hsl(var(--muted))",
          foreground: "hsl(var(--muted-foreground))",
        },
        accent: {
          DEFAULT: "hsl(var(--accent))",
          foreground: "hsl(var(--accent-foreground))",
        },
        popover: {
          DEFAULT: "hsl(var(--popover))",
          foreground: "hsl(var(--popover-foreground))",
        },
        card: {
          DEFAULT: "hsl(var(--card))",
          foreground: "hsl(var(--card-foreground))",
        },
      },
      borderRadius: {
        lg: "var(--radius)",
        md: "calc(var(--radius) - 2px)",
        sm: "calc(var(--radius) - 4px)",
      },
      keyframes: {
        "accordion-down": {
          from: { height: "0" },
          to: { height: "var(--radix-accordion-content-height)" },
        },
        "accordion-up": {
          from: { height: "var(--radix-accordion-content-height)" },
          to: { height: "0" },
        },
      },
      animation: {
        "accordion-down": "accordion-down 0.2s ease-out",
        "accordion-up": "accordion-up 0.2s ease-out",
      },
    },
  },
  plugins: [require("tailwindcss-animate")],
} satisfies Config

export default config

================
File: tsconfig.json
================
{
  "compilerOptions": {
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "target": "ES6",
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}
